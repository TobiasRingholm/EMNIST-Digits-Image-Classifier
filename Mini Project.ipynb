{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2362a513",
   "metadata": {},
   "source": [
    "# Image classification using the Emnist digits dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4ca81f",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b23900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import sklearn\n",
    "import time\n",
    "import joblib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f24388",
   "metadata": {},
   "source": [
    "## Callback setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15de93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the root log directory.\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7952e90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function which will generate a subdirectory path based on current date and time.\n",
    "# This is needed for TensorBoard.\n",
    "def get_run_logdir():\n",
    "    run_id =time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa73c51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define callbacks.\n",
    "\n",
    "# ModelCheckpoint.\n",
    "# Saves checkpoints of the model at regular intervals.\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"emnist_digits.h5\", save_best_only=True)\n",
    "\n",
    "# EarlyStopping (with rollback to the best model).\n",
    "# Interrupts training when it measures no progress on the validation set for 10 epochs.\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "# TensorBoard.\n",
    "# Saves data in log files at regular intervals to later display this data in TensorBoard.\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "# Performance Scheduling.\n",
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7d51d5",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30551474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I decided to install emnist by using:\n",
    "# python3 â€“m pip install emnist\n",
    "# This is to download and load the dataset.\n",
    "from emnist import extract_training_samples, extract_test_samples\n",
    "emnist_digits = extract_training_samples, extract_test_samples\n",
    "x_train_full, y_train_full = extract_training_samples('digits')\n",
    "x_test, y_test = extract_test_samples('digits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c40d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the size and dimension of the data.\n",
    "# Each pixel intesity is represented as a byte (0 to 255).\n",
    "x_train_full.shape, x_train_full.dtype, y_train_full.shape, y_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddc0bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The full data is split into a validation and a smaller training set.\n",
    "# The pixel intensities are scaled down to a 0-1 range and converted to a float.\n",
    "x_valid, x_train = x_train_full[:5000] / 255., x_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "x_test = x_test / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae88094",
   "metadata": {},
   "source": [
    "### Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c78393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the size and dimension of the splitted data.\n",
    "x_train.shape, x_valid.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa0118f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot one image of each using Matplotlib's imshow() function, which a binary color map:\n",
    "plt.imshow(x_train[0], cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22daa967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The labels are the class IDs from 0 to 9.\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d110c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the class names.\n",
    "class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c93c747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the class name of the first iamgine in the training set.\n",
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0f055b",
   "metadata": {},
   "source": [
    "## Standardize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d802c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean for each pixel.\n",
    "pixel_means = x_train.mean(axis=0)\n",
    "pixel_means.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fe7907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the standard deviation for each pixel.\n",
    "pixel_stds = (x_train.std(axis=0)+0.000001)\n",
    "pixel_stds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd3e8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the inputs to mean 0 and standard deviation 1 to achieve self-normalization with SELU and LeCun.\n",
    "x_train_standardized = (x_train - pixel_means) / pixel_stds\n",
    "\n",
    "x_valid_standardized = (x_valid - x_valid.mean(axis=0)) / (x_valid.std(axis=0)+0.000001)\n",
    "x_test_standardized = (x_test - x_test.mean(axis=0)) / (x_test.std(axis=0)+0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2d019c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate that the mean is close to 0 for each pixel.\n",
    "x_train_standardized.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84bc722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate that the standard deviation is close to 1 for each pixel.\n",
    "x_train_standardized.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d77156",
   "metadata": {},
   "source": [
    "## Create a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f143abca",
   "metadata": {},
   "source": [
    "### Sequential\n",
    "Skip this is if you wish to run the model with hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc9280a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input layer is made by flatten to convert each input image into a 1-dimensional array.\n",
    "# Two hidden layers is made by dense to make them fully connected (300 neurons and relu).\n",
    "# Alpha dropout regularization is used in the last hidden layer.\n",
    "# The output layer contains one neuron per class. Softmax because multiclass classifier.\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for layer in range(7):\n",
    "    model.add(keras.layers.Dense(400, activation=\"selu\", kernel_initializer=\"lecun_normal\"))\n",
    "    #model.add(keras.layers.Dense(400, activation=\"relu\"))\n",
    "model.add(keras.layers.AlphaDropout(rate=0.2))\n",
    "#model.add(keras.layers.Dropout(rate=0.2))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd369cbd",
   "metadata": {},
   "source": [
    "#### Show information about the sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d3c1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68020e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model.layers[1]\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce770e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b661b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa3471a",
   "metadata": {},
   "outputs": [],
   "source": [
    "biases, biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc53a5a4",
   "metadata": {},
   "source": [
    "#### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5ffd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer = keras.optimizers.SGD(momentum=0.9),\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be5d964",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "(If you wish to load an already compiled and trained model scroll to the end of the notebook.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b63e0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras will measure the loss and the extra metrics on the validation set at the end of each epoch.\n",
    "# The number of epochs is here set to 30.\n",
    "# We use the default batch-size.\n",
    "history = model.fit(x_train_standardized, y_train, epochs=30,\n",
    "                    validation_data=(x_valid_standardized, y_valid),\n",
    "                    callbacks=[lr_scheduler, checkpoint_cb, early_stopping_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dbb314",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4347d857",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2a3ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e2edde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the learning curves.\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(15,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a23f49f",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e64396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set.\n",
    "model.evaluate(x_test_standardized, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ef05f5",
   "metadata": {},
   "source": [
    "##### Observations:\n",
    "Using 400 neurons and 7 hidden layers, selu, lecun, all callbacks and alpha dropout:<br> [0.05326846241950989, 0.9910749793052673]\n",
    "\n",
    "Using 300 neurons and 2 hidden layers, selu, lecun, all callbacks and alpha dropout:<br> [0.08781340718269348, 0.9824000000953674]\n",
    "\n",
    "Using 300 neurons and 2 hidden layers, relu, all callbacks and alpha dropout: <br> [0.04303058236837387, 0.9913750290870667]\n",
    "\n",
    "Using 300 neurons and 2 hidden layers, relu, all callbacks and dropout: <br> [0.030846111476421356, 0.9906749725341797]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0e2b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with probabilities for the first three instances in the training set.\n",
    "x_new = x_test_standardized[:3]\n",
    "y_proba = model.predict(x_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7efd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions without probabilities.\n",
    "y_pred = np.argmax(model.predict(x_new), axis=-1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7787958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the predictions were correct.\n",
    "y_new = y_test[:3]\n",
    "y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f587292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the names of the predicted.\n",
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e9897f",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning with RandomizedSearchCV\n",
    "(If you wish to load an already compiled and trained model scroll to the end of the notebook.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4987f27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that will build and compile a Keras model.\n",
    "def build_model(n_hidden=1, n_neurons=100, learning_rate=3e-3, input_shape=[28, 28]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        #model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "        model.add(keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"))\n",
    "    model.add(keras.layers.AlphaDropout(rate=0.2))\n",
    "    model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "    optimizer = keras.optimizers.SGD(momentum=0.9)\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c9dbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the Keras model in a Scikit-Learn KerasClassifier.\n",
    "keras_clf = keras.wrappers.scikit_learn.KerasClassifier(build_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54805b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define hyperparameter set and ranges to explore.\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [1, 2, 3, 7, 10],\n",
    "    \"n_neurons\": [100, 200, 300, 400, 600]\n",
    "}\n",
    "\n",
    "# Create an instances of RandomizedSearchCV\n",
    "rnd_search_cv = RandomizedSearchCV(keras_clf, param_distribs, n_iter=25, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Search\n",
    "rnd_search_cv.fit(x_train_standardized, y_train, epochs=60,\n",
    "                 validation_data=(x_valid_standardized, y_valid),\n",
    "                 callbacks=[lr_scheduler, checkpoint_cb, tensorboard_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c15153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the parameters and score of the best model.\n",
    "rnd_search_cv.best_params_, rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff0e2c8",
   "metadata": {},
   "source": [
    "##### Observations:\n",
    "Using relu the best params and score was: {'n_neurons': 300, 'n_hidden': 2}, 0.9896297852198283 <br>\n",
    "Using selu and lecun the best params and score was:({'n_neurons': 400, 'n_hidden': 7}, 0.9887957572937012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70dfb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model for the best estimator and evaluate it on the test set.\n",
    "rnd_search_model = rnd_search_cv.best_estimator_.model\n",
    "rnd_search_model.evaluate(x_test_standardized, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2186333c",
   "metadata": {},
   "source": [
    "##### Observations:\n",
    "Using relu the best accuracy was: [0.04202648624777794, 0.9904999732971191] <br>\n",
    "Using selu and lecun the best accuracy was: [0.05357888340950012, 0.9907749891281128]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c94406d",
   "metadata": {},
   "source": [
    "### Display learning curves in TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908df314",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fc5fb9",
   "metadata": {},
   "source": [
    "### Save and load a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6095f69a",
   "metadata": {},
   "source": [
    "#### Keras object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cca7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"emnist_digits.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a7629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"emnist_digits.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b3694e",
   "metadata": {},
   "source": [
    "#### RandomizedSearchCV object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f2c8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save rnd_search_cv model\n",
    "joblib.dump(rnd_search_cv, 'rnd_search_cv-selu.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f562167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore rnd_search_cv model for further usage\n",
    "joblib.load(\"rnd_search_cv.pkl\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
